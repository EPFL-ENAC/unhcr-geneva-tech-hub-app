{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1924a26-7606-49c3-be38-d1bc9b9f3501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "import subprocess\n",
    "import tarfile\n",
    "import time\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "class TSSData:\n",
    "    def __init__(self):\n",
    "        # Inizializza le variabili di ambiente\n",
    "        self.source_directory = os.getenv('SOURCE_DIR', '/data')\n",
    "        self.destination_directory = os.getenv('DEST_DIR', '/data')\n",
    "        self.couchdb_user = os.getenv('COUCHDB_USER', 'admin')\n",
    "        self.couchdb_password = 'couchdb'\n",
    "        self.couchdb_host = os.getenv('COUCHDB_HOST', 'couchdb')\n",
    "        self.couchdb_dump_script = os.getenv('COUCHDB_DUMP_SCRIPT', '/home/jovyan/work/couchdb-dump.sh')\n",
    "        self.account_name = os.getenv('AZURE_ACCOUNT_NAME')\n",
    "        self.account_key = os.getenv('AZURE_ACCOUNT_KEY')\n",
    "        self.container_name = os.getenv('AZURE_CONTAINER')\n",
    "        self.retention_days = int(os.getenv('RETENTION_DAYS', 7))\n",
    "        self.connection_string = f'DefaultEndpointsProtocol=https;AccountName={self.account_name};AccountKey={self.account_key};EndpointSuffix=core.windows.net'\n",
    "\n",
    "    def data_dump(self):\n",
    "        # Imposta il timestamp per il nome del file\n",
    "        current_time_ms = int(round(time.time() * 1000))\n",
    "        backup_file = f'tss/{current_time_ms}/backup.tar.gz'\n",
    "        local_backup_file = f'/tmp/backup_{current_time_ms}.tar.gz'\n",
    "\n",
    "        # Comprimi la directory source\n",
    "        with tarfile.open(local_backup_file, 'w:gz') as tar:\n",
    "            tar.add(self.source_directory, arcname=os.path.basename(self.source_directory))\n",
    "\n",
    "        # Crea un client Blob Service e carica il file\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(self.connection_string)\n",
    "        blob_client = blob_service_client.get_blob_client(container=self.container_name, blob=backup_file)\n",
    "\n",
    "        with open(local_backup_file, 'rb') as data:\n",
    "            blob_client.upload_blob(data, overwrite=True)\n",
    "\n",
    "        print(f'Successfully uploaded {backup_file} to Azure Blob Storage.')\n",
    "\n",
    "        # Elimina il file tar locale dopo l'upload\n",
    "        os.remove(local_backup_file)\n",
    "\n",
    "        # Pulizia dei vecchi backup\n",
    "        self.cleanup_old_backups(blob_service_client)\n",
    "\n",
    "    def couchdb_data_dump(self):\n",
    "        # Imposta il timestamp per il nome del file e crea una directory per i dump\n",
    "        current_time_ms = int(round(time.time() * 1000))\n",
    "        backup_directory = f'/tmp/backup_{current_time_ms}'\n",
    "        os.makedirs(backup_directory, exist_ok=True)\n",
    "        \n",
    "        # Elenca tutti i database in CouchDB\n",
    "        databases = subprocess.check_output(\n",
    "            f'curl -s -u {self.couchdb_user}:{self.couchdb_password} http://{self.couchdb_host}:5984/_all_dbs',\n",
    "            shell=True\n",
    "        ).decode('utf-8')\n",
    "        databases = databases.strip('[]').replace('\"', '').split(',')\n",
    "\n",
    "        # Effettua il dump di ogni database\n",
    "        for db in databases:\n",
    "            subprocess.call(\n",
    "                f'bash {self.couchdb_dump_script} -b -H {self.couchdb_host} -d {db} -f {backup_directory}/{db}.json -u {self.couchdb_user} -p {self.couchdb_password}',\n",
    "                shell=True\n",
    "            )\n",
    "\n",
    "        # Comprimi la directory del backup\n",
    "        local_backup_file = f'/tmp/backup_{current_time_ms}.tar.gz'\n",
    "        with tarfile.open(local_backup_file, 'w:gz') as tar:\n",
    "            tar.add(backup_directory, arcname=os.path.basename(backup_directory))\n",
    "\n",
    "        # Crea un client Blob Service e carica il file\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(self.connection_string)\n",
    "        backup_blob_name = f'tss/{current_time_ms}/backup.tar.gz'\n",
    "        blob_client = blob_service_client.get_blob_client(container=self.container_name, blob=backup_blob_name)\n",
    "        with open(local_backup_file, 'rb') as data:\n",
    "            blob_client.upload_blob(data, overwrite=True)\n",
    "        print(f'Successfully uploaded {backup_blob_name} to Azure Blob Storage.')\n",
    "\n",
    "        # Pulizia: rimuovi i file locali e la directory del backup\n",
    "        shutil.rmtree(backup_directory)\n",
    "        os.remove(local_backup_file)\n",
    "\n",
    "        # Pulizia dei vecchi backup\n",
    "        self.cleanup_old_backups(blob_service_client)\n",
    "\n",
    "    def cleanup_old_backups(self, blob_service_client):\n",
    "        # Ottieni l'elenco di tutti i blob nel container\n",
    "        container_client = blob_service_client.get_container_client(self.container_name)\n",
    "        blob_list = container_client.list_blobs(name_starts_with='tss/')\n",
    "\n",
    "        # Ordina i blob per nome (che include il timestamp)\n",
    "        sorted_blobs = sorted(blob_list, key=lambda blob: blob.name, reverse=True)\n",
    "\n",
    "        # Conserva solo i più recenti in base al valore di retention_days\n",
    "        old_blobs = sorted_blobs[self.retention_days:]\n",
    "\n",
    "        for blob in old_blobs:\n",
    "            print(f'Deleting old backup: {blob.name}')\n",
    "            blob_client = container_client.get_blob_client(blob=blob.name)\n",
    "            blob_client.delete_blob()\n",
    "\n",
    "    def restore_data(self, backup_name):\n",
    "        # Costruisci il nome del file di backup e il percorso del file locale\n",
    "        backup_file = f'tss/{backup_name}/backup.tar.gz'\n",
    "        local_backup_file = os.path.join('/tmp', f'backup_{backup_name}.tar.gz')\n",
    "\n",
    "        # Scarica e decomprimi il backup\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(self.connection_string)\n",
    "        blob_client = blob_service_client.get_blob_client(container=self.container_name, blob=backup_file)\n",
    "        print(f'Downloading {backup_file} from Azure Blob Storage...')\n",
    "        os.makedirs(self.destination_directory, exist_ok=True)\n",
    "        with open(local_backup_file, 'wb') as download_file:\n",
    "            download_blob = blob_client.download_blob()\n",
    "            download_blob.readinto(download_file)\n",
    "        print(f'Extracting {local_backup_file} to temporary directory...')\n",
    "        temp_extract_dir = os.path.join('/tmp', f'extract_{backup_name}')\n",
    "        os.makedirs(temp_extract_dir, exist_ok=True)\n",
    "        with tarfile.open(local_backup_file, 'r:gz') as tar:\n",
    "            tar.extractall(path=temp_extract_dir)\n",
    "\n",
    "        # Sposta il contenuto dalla directory estratta alla directory di destinazione\n",
    "        if os.path.exists(temp_extract_dir):\n",
    "            for root_dir in os.listdir(temp_extract_dir):\n",
    "                intermediate_dir = os.path.join(temp_extract_dir, root_dir)\n",
    "                if os.path.isdir(intermediate_dir):\n",
    "                    for item in os.listdir(intermediate_dir):\n",
    "                        source = os.path.join(intermediate_dir, item)\n",
    "                        destination = os.path.join(self.destination_directory, item)\n",
    "                        try:\n",
    "                            if os.path.isdir(source):\n",
    "                                if os.path.exists(destination):\n",
    "                                    shutil.rmtree(destination)  # Rimuovi la directory esistente\n",
    "                                shutil.move(source, destination)\n",
    "                            else:\n",
    "                                if os.path.exists(destination):\n",
    "                                    os.remove(destination)  # Rimuovi il file esistente\n",
    "                                shutil.move(source, destination)\n",
    "                        except FileNotFoundError:\n",
    "                            print(f\"File or directory {destination} not found during removal.\")\n",
    "                else:  # Se non è una directory, sposta direttamente il file\n",
    "                    destination = os.path.join(self.destination_directory, root_dir)\n",
    "                    try:\n",
    "                        if os.path.exists(destination):\n",
    "                            os.remove(destination)\n",
    "                        shutil.move(intermediate_dir, destination)\n",
    "                    except FileNotFoundError:\n",
    "                        print(f\"File or directory {destination} not found during removal.\")\n",
    "\n",
    "        # Pulizia: rimuovi il file tar e la directory temporanea\n",
    "        try:\n",
    "            os.remove(local_backup_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {local_backup_file} not found for removal.\")\n",
    "        try:\n",
    "            shutil.rmtree(temp_extract_dir)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Temporary directory {temp_extract_dir} not found for removal.\")\n",
    "\n",
    "        print(f'Backup {backup_name} restored successfully.')\n",
    "\n",
    "    def couch_db_restore_data(self, backup_name):\n",
    "        # Costruisci il nome del file di backup e il percorso del file locale\n",
    "        backup_file = f'tss/{backup_name}/backup.tar.gz'\n",
    "        local_backup_file = os.path.join('/tmp', f'backup_{backup_name}.tar.gz')\n",
    "    \n",
    "        # Scarica e decomprimi il backup\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(self.connection_string)\n",
    "        blob_client = blob_service_client.get_blob_client(container=self.container_name, blob=backup_file)\n",
    "        print(f'Downloading {backup_file} from Azure Blob Storage...')\n",
    "        os.makedirs(self.destination_directory, exist_ok=True)\n",
    "        with open(local_backup_file, 'wb') as download_file:\n",
    "            download_blob = blob_client.download_blob()\n",
    "            download_blob.readinto(download_file)\n",
    "        print(f'Extracting {local_backup_file} to temporary directory...')\n",
    "        temp_extract_dir = os.path.join('/tmp', f'extract_{backup_name}')\n",
    "        os.makedirs(temp_extract_dir, exist_ok=True)\n",
    "        with tarfile.open(local_backup_file, 'r:gz') as tar:\n",
    "            tar.extractall(path=temp_extract_dir)\n",
    "    \n",
    "        # Itera attraverso i file JSON estratti per il ripristino dei dati\n",
    "        for root_dir, dirs, files in os.walk(temp_extract_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.json'):\n",
    "                    db_name = file.replace('.json', '')  # Il nome del database è derivato dal nome del file\n",
    "                    db_url = f'http://{self.couchdb_user}:{self.couchdb_password}@{self.couchdb_host}:5984/{db_name}'\n",
    "    \n",
    "                    # Elimina il database se esiste\n",
    "                    resp = requests.get(db_url)\n",
    "                    if resp.status_code != 404:  # Se il database esiste\n",
    "                        requests.delete(db_url)  # Elimina il database\n",
    "    \n",
    "                    # Ricrea il database\n",
    "                    requests.put(db_url)\n",
    "    \n",
    "                    # Esegue il ripristino del database dal file JSON\n",
    "                    restore_file_path = os.path.join(root_dir, file)\n",
    "                    restore_command = (\n",
    "                        f'bash {self.couchdb_dump_script} -r -H {self.couchdb_host} -d {db_name} '\n",
    "                        f'-f {restore_file_path} -u {self.couchdb_user} -p {self.couchdb_password}'\n",
    "                    )\n",
    "                    subprocess.call(restore_command, shell=True)\n",
    "    \n",
    "        # Pulizia: rimuovi il file tar e la directory temporanea\n",
    "        try:\n",
    "            os.remove(local_backup_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {local_backup_file} not found for removal.\")\n",
    "        try:\n",
    "            shutil.rmtree(temp_extract_dir)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Temporary directory {temp_extract_dir} not found for removal.\")\n",
    "    \n",
    "        print(f'Backup {backup_name} restored successfully.')\n",
    "\n",
    "    def couchdbbackup_dump(self):\n",
    "        # Imposta il timestamp per il nome del file\n",
    "        current_time_ms = int(round(time.time() * 1000))\n",
    "        backup_directory = f'/tmp/backup_{current_time_ms}'\n",
    "        os.makedirs(backup_directory, exist_ok=True)\n",
    "        \n",
    "        # Ottieni l'elenco dei database da backuppare\n",
    "        databases = subprocess.check_output(\n",
    "            f'curl -s -u {self.couchdb_user}:{self.couchdb_password} http://{self.couchdb_host}:5984/_all_dbs',\n",
    "            shell=True\n",
    "        ).decode('utf-8')\n",
    "        databases = databases.strip('[]').replace('\"', '').split(',')\n",
    "\n",
    "        # Esegue il backup di ogni database\n",
    "        for db in databases:\n",
    "            print(db)\n",
    "            backup_file_path = f'{backup_directory}/{db}.txt'\n",
    "            subprocess.call(\n",
    "                f'couchbackup --db {db} > {backup_file_path}',\n",
    "                shell=True\n",
    "            )\n",
    "\n",
    "        # Comprimi la directory del backup\n",
    "        local_backup_file = f'/tmp/backup_{current_time_ms}.tar.gz'\n",
    "        with tarfile.open(local_backup_file, 'w:gz') as tar:\n",
    "            tar.add(backup_directory, arcname=os.path.basename(backup_directory))\n",
    "\n",
    "        # Carica il file tar in Azure Blob Storage\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(self.connection_string)\n",
    "        backup_blob_name = f'tss/{current_time_ms}/backup.tar.gz'\n",
    "        blob_client = blob_service_client.get_blob_client(container=self.container_name, blob=backup_blob_name)\n",
    "        with open(local_backup_file, 'rb') as data:\n",
    "            blob_client.upload_blob(data, overwrite=True)\n",
    "        print(f'Successfully uploaded {backup_blob_name} to Azure Blob Storage.')\n",
    "\n",
    "        # Pulizia: rimuovi i file locali e la directory del backup\n",
    "        shutil.rmtree(backup_directory)\n",
    "        os.remove(local_backup_file)\n",
    "\n",
    "    def couchdbbackup_restore(self, backup_name):\n",
    "        # Costruisci il nome del file di backup e il percorso del file locale\n",
    "        backup_file = f'tss/{backup_name}/backup.tar.gz'\n",
    "        local_backup_file = os.path.join('/tmp', f'backup_{backup_name}.tar.gz')\n",
    "\n",
    "        # Scarica e decomprimi il backup\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(self.connection_string)\n",
    "        blob_client = blob_service_client.get_blob_client(container=self.container_name, blob=backup_file)\n",
    "        print(f'Downloading {backup_file} from Azure Blob Storage...')\n",
    "        os.makedirs(self.destination_directory, exist_ok=True)\n",
    "        with open(local_backup_file, 'wb') as download_file:\n",
    "            download_blob = blob_client.download_blob()\n",
    "            download_blob.readinto(download_file)\n",
    "        print(f'Extracting {local_backup_file} to temporary directory...')\n",
    "        temp_extract_dir = os.path.join('/tmp', f'extract_{backup_name}')\n",
    "        os.makedirs(temp_extract_dir, exist_ok=True)\n",
    "        with tarfile.open(local_backup_file, 'r:gz') as tar:\n",
    "            tar.extractall(path=temp_extract_dir)\n",
    "\n",
    "        # Itera attraverso i file estratti per il ripristino dei dati\n",
    "        for file in os.listdir(temp_extract_dir):\n",
    "            if file.endswith('.txt'):\n",
    "                db_name = file.replace('.txt', '')  # Il nome del database è derivato dal nome del file\n",
    "                db_url = f'http://{self.couchdb_user}:{self.couchdb_password}@{self.couchdb_host}:5984/{db_name}'\n",
    "\n",
    "                # Elimina il database se esiste e ricrealo\n",
    "                requests.delete(db_url)\n",
    "                requests.put(db_url)\n",
    "\n",
    "                # Esegue il ripristino del database dal file\n",
    "                restore_file_path = os.path.join(temp_extract_dir, file)\n",
    "                subprocess.call(\n",
    "                    f'cat {restore_file_path} | couchrestore --db {db_name}',\n",
    "                    shell=True\n",
    "                )\n",
    "\n",
    "        # Pulizia: rimuovi il file tar e la directory temporanea\n",
    "        os.remove(local_backup_file)\n",
    "        shutil.rmtree(temp_extract_dir)\n",
    "\n",
    "        print(f'Backup {backup_name} restored successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3afbfd7-52b1-453e-9fc8-653029ad8aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_replicator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Performing backup on http://****:****@couchdb:5984/_replicator using configuration:\n",
      "{\n",
      "  \"bufferSize\": 500,\n",
      "  \"log\": \"/tmp/couchbackup-iKUIOv/1709566987375\",\n",
      "  \"mode\": \"full\",\n",
      "  \"parallelism\": 5,\n",
      "  \"requestTimeout\": 120000,\n",
      "  \"resume\": false\n",
      "}\n",
      "================================================================================\n",
      "2024-03-04T15:43:07.378Z couchbackup:backup Fetching all database changes...\n",
      "2024-03-04T15:44:04.510Z couchbackup:backup Finished - Total document revisions written: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Performing backup on http://****:****@couchdb:5984/_users using configuration:\n",
      "{\n",
      "  \"bufferSize\": 500,\n",
      "  \"log\": \"/tmp/couchbackup-vnlKEC/1709567044736\",\n",
      "  \"mode\": \"full\",\n",
      "  \"parallelism\": 5,\n",
      "  \"requestTimeout\": 120000,\n",
      "  \"resume\": false\n",
      "}\n",
      "================================================================================\n",
      "2024-03-04T15:44:04.739Z couchbackup:backup Fetching all database changes...\n",
      "2024-03-04T15:44:04.810Z couchbackup:backup:batch Total batches received: 1\n",
      "2024-03-04T15:44:04.837Z couchbackup:backup:batch Written batch ID: 0 Total document revisions written: 95 Time: 0.045\n",
      "2024-03-04T15:44:04.837Z couchbackup:backup Finished - Total document revisions written: 95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ghg_projects_1696578512055758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Performing backup on http://****:****@couchdb:5984/ghg_projects_1696578512055758 using configuration:\n",
      "{\n",
      "  \"bufferSize\": 500,\n",
      "  \"log\": \"/tmp/couchbackup-wOtx4l/1709567045031\",\n",
      "  \"mode\": \"full\",\n",
      "  \"parallelism\": 5,\n",
      "  \"requestTimeout\": 120000,\n",
      "  \"resume\": false\n",
      "}\n",
      "================================================================================\n",
      "2024-03-04T15:44:05.033Z couchbackup:backup Fetching all database changes...\n",
      "2024-03-04T15:44:05.103Z couchbackup:backup:batch Total batches received: 1\n",
      "2024-03-04T15:44:05.141Z couchbackup:backup:batch Written batch ID: 0 Total document revisions written: 129 Time: 0.053\n",
      "2024-03-04T15:44:05.141Z couchbackup:backup Finished - Total document revisions written: 129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shelter_projects_1698666594213623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Performing backup on http://****:****@couchdb:5984/shelter_projects_1698666594213623 using configuration:\n",
      "{\n",
      "  \"bufferSize\": 500,\n",
      "  \"log\": \"/tmp/couchbackup-SeTZ5K/1709567045327\",\n",
      "  \"mode\": \"full\",\n",
      "  \"parallelism\": 5,\n",
      "  \"requestTimeout\": 120000,\n",
      "  \"resume\": false\n",
      "}\n",
      "================================================================================\n",
      "2024-03-04T15:44:05.330Z couchbackup:backup Fetching all database changes...\n",
      "2024-03-04T15:44:05.400Z couchbackup:backup:batch Total batches received: 1\n",
      "2024-03-04T15:44:05.489Z couchbackup:backup:batch Written batch ID: 0 Total document revisions written: 122 Time: 0.105\n",
      "2024-03-04T15:44:05.489Z couchbackup:backup Finished - Total document revisions written: 122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Performing backup on http://****:****@couchdb:5984/tokens%5D using configuration:\n",
      "{\n",
      "  \"bufferSize\": 500,\n",
      "  \"log\": \"/tmp/couchbackup-K48IUS/1709567045709\",\n",
      "  \"mode\": \"full\",\n",
      "  \"parallelism\": 5,\n",
      "  \"requestTimeout\": 120000,\n",
      "  \"resume\": false\n",
      "}\n",
      "================================================================================\n",
      "2024-03-04T15:44:05.712Z couchbackup:backup Fetching all database changes...\n",
      "ERROR: Object Not Found Ensure the backup source database exists.\n",
      "/bin/sh: 3: .txt: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded tss/1709566987069/backup.tar.gz to Azure Blob Storage.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tss_data = TSSData()\n",
    "    tss_data.couchdbbackup_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5049861-a0ab-462e-8e93-4b77beac109b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
